{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('edges3.csv')\n",
    "df2 = pd.read_excel('node3_cml.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_id</th>\n",
       "      <th>v_id_1</th>\n",
       "      <th>v_id_2</th>\n",
       "      <th>voltage</th>\n",
       "      <th>cables</th>\n",
       "      <th>wires</th>\n",
       "      <th>length_m</th>\n",
       "      <th>r</th>\n",
       "      <th>x</th>\n",
       "      <th>c</th>\n",
       "      <th>i_th_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43379.0</td>\n",
       "      <td>1.735160</td>\n",
       "      <td>13.881280</td>\n",
       "      <td>498.8585</td>\n",
       "      <td>112.78540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72686.0</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>18.171500</td>\n",
       "      <td>995.7982</td>\n",
       "      <td>1511.86880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33943.0</td>\n",
       "      <td>0.678860</td>\n",
       "      <td>10.861760</td>\n",
       "      <td>390.3445</td>\n",
       "      <td>176.50360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33471.0</td>\n",
       "      <td>0.209194</td>\n",
       "      <td>8.367750</td>\n",
       "      <td>458.5527</td>\n",
       "      <td>348.09840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28163.0</td>\n",
       "      <td>0.088009</td>\n",
       "      <td>7.040750</td>\n",
       "      <td>385.8331</td>\n",
       "      <td>585.79040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>0.253184</td>\n",
       "      <td>9.0988</td>\n",
       "      <td>2.10912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>762.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.196608</td>\n",
       "      <td>7.0656</td>\n",
       "      <td>2.11640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>1.008832</td>\n",
       "      <td>36.2549</td>\n",
       "      <td>8.19676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>764.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>10.3891</td>\n",
       "      <td>2.70972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>765.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>6.3480</td>\n",
       "      <td>1.95416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l_id  v_id_1  v_id_2   voltage  cables  wires  length_m         r  \\\n",
       "0      1.0     1.0     2.0  220000.0     3.0    2.0   43379.0  1.735160   \n",
       "1      2.0     3.0     4.0  380000.0     6.0    4.0   72686.0  0.227144   \n",
       "2      3.0     5.0     6.0  220000.0     6.0    2.0   33943.0  0.678860   \n",
       "3      4.0     7.0     5.0  380000.0     3.0    4.0   33471.0  0.209194   \n",
       "4      5.0     8.0     9.0  380000.0     6.0    4.0   28163.0  0.088009   \n",
       "..     ...     ...     ...       ...     ...    ...       ...       ...   \n",
       "760  761.0   474.0   476.0  220000.0     9.0    1.8     770.0  0.038376   \n",
       "761  762.0   475.0   476.0  220000.0     9.0    2.4     661.0  0.020584   \n",
       "762  763.0   477.0   479.0  220000.0    12.0    2.0    3315.0  0.126104   \n",
       "763  764.0   225.0   479.0  220000.0    12.0    2.0     897.0  0.033360   \n",
       "764  765.0   478.0   479.0  220000.0    12.0    2.4     488.0  0.018088   \n",
       "\n",
       "             x         c    i_th_max  \n",
       "0    13.881280  498.8585   112.78540  \n",
       "1    18.171500  995.7982  1511.86880  \n",
       "2    10.861760  390.3445   176.50360  \n",
       "3     8.367750  458.5527   348.09840  \n",
       "4     7.040750  385.8331   585.79040  \n",
       "..         ...       ...         ...  \n",
       "760   0.253184    9.0988     2.10912  \n",
       "761   0.196608    7.0656     2.11640  \n",
       "762   1.008832   36.2549     8.19676  \n",
       "763   0.289088   10.3891     2.70972  \n",
       "764   0.176640    6.3480     1.95416  \n",
       "\n",
       "[765 rows x 11 columns]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>typ</th>\n",
       "      <th>voltage</th>\n",
       "      <th>eigen_centrality</th>\n",
       "      <th>closeness_centrality</th>\n",
       "      <th>clustering_coefficient</th>\n",
       "      <th>load_centrality</th>\n",
       "      <th>avg_shortest_path_length</th>\n",
       "      <th>average_neighbor_degree</th>\n",
       "      <th>node_strength</th>\n",
       "      <th>criticality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.522576</td>\n",
       "      <td>52.360409</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.113210</td>\n",
       "      <td>52.543853</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>1.838136e-31</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1260000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.389745</td>\n",
       "      <td>52.026313</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>7.071928e-44</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.125265</td>\n",
       "      <td>52.538264</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>1.813950e-37</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.366275</td>\n",
       "      <td>52.284647</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>7.071928e-44</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2400000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>8.872260</td>\n",
       "      <td>50.129725</td>\n",
       "      <td>substation</td>\n",
       "      <td>110000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>8.743261</td>\n",
       "      <td>50.162338</td>\n",
       "      <td>auxillary_T_node</td>\n",
       "      <td>220000</td>\n",
       "      <td>6.141411e-44</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>660000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>7.957537</td>\n",
       "      <td>47.572159</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>478</td>\n",
       "      <td>7.958491</td>\n",
       "      <td>47.579148</td>\n",
       "      <td>generator</td>\n",
       "      <td>380000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>7.950278</td>\n",
       "      <td>47.591674</td>\n",
       "      <td>auxillary_T_node</td>\n",
       "      <td>220000</td>\n",
       "      <td>2.087394e-21</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>660000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     v_id        lon        lat               typ  voltage  eigen_centrality  \\\n",
       "0       1   9.522576  52.360409        substation   220000      9.305167e-51   \n",
       "1       2   9.113210  52.543853        substation   220000      1.838136e-31   \n",
       "2       3   9.389745  52.026313        substation   380000      7.071928e-44   \n",
       "3       4   9.125265  52.538264        substation   380000      1.813950e-37   \n",
       "4       5  10.366275  52.284647        substation   380000      7.071928e-44   \n",
       "..    ...        ...        ...               ...      ...               ...   \n",
       "474   475   8.872260  50.129725        substation   110000      9.305167e-51   \n",
       "475   476   8.743261  50.162338  auxillary_T_node   220000      6.141411e-44   \n",
       "476   477   7.957537  47.572159        substation   220000      9.305167e-51   \n",
       "477   478   7.958491  47.579148         generator   380000      9.305167e-51   \n",
       "478   479   7.950278  47.591674  auxillary_T_node   220000      2.087394e-21   \n",
       "\n",
       "     closeness_centrality  clustering_coefficient  load_centrality  \\\n",
       "0                0.000000                    0.00         0.000000   \n",
       "1                0.006834                    0.05         0.000197   \n",
       "2                0.004184                    0.05         0.000171   \n",
       "3                0.006538                    0.00         0.000395   \n",
       "4                0.004184                    0.00         0.000110   \n",
       "..                    ...                     ...              ...   \n",
       "474              0.000000                    0.00         0.000000   \n",
       "475              0.006276                    0.00         0.000000   \n",
       "476              0.000000                    0.00         0.000000   \n",
       "477              0.000000                    0.00         0.000000   \n",
       "478              0.009375                    0.00         0.000000   \n",
       "\n",
       "     avg_shortest_path_length  average_neighbor_degree  node_strength  \\\n",
       "0                    2.222222                 3.000000         220000   \n",
       "1                    1.500000                 1.333333        1260000   \n",
       "2                    3.000000                 1.000000        1900000   \n",
       "3                    2.350000                 2.000000        1900000   \n",
       "4                    1.500000                 1.333333        2400000   \n",
       "..                        ...                      ...            ...   \n",
       "474                  0.500000                 0.000000         220000   \n",
       "475                  0.000000                 0.000000         660000   \n",
       "476                  0.500000                 0.000000         220000   \n",
       "477                  0.500000                 0.000000         220000   \n",
       "478                  0.000000                 0.000000         660000   \n",
       "\n",
       "    criticality_label  \n",
       "0                 Low  \n",
       "1              Severe  \n",
       "2              Severe  \n",
       "3              Severe  \n",
       "4              Severe  \n",
       "..                ...  \n",
       "474               Low  \n",
       "475              High  \n",
       "476               Low  \n",
       "477               Low  \n",
       "478              High  \n",
       "\n",
       "[479 rows x 13 columns]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Handle Categorical Variable in df2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the 'typ' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "typ_encoded = encoder.fit_transform(df2[['typ']])\n",
    "\n",
    "# Convert to DataFrame and concatenate with df2\n",
    "typ_encoded_df = pd.DataFrame(typ_encoded, columns=encoder.get_feature_names_out(['typ']))\n",
    "df2 = pd.concat([df2.drop('typ', axis=1), typ_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Numerical Features in df2 and df1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize node features in df2\n",
    "node_feature_cols = [col for col in df2.columns if col not in ['v_id', 'criticality_label', *encoder.get_feature_names_out(['typ'])]]\n",
    "scaler = StandardScaler()\n",
    "df2[node_feature_cols] = scaler.fit_transform(df2[node_feature_cols])\n",
    "\n",
    "# Standardize edge features in df1\n",
    "edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "df1[edge_feature_cols] = scaler.fit_transform(df1[edge_feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data for PyTorch Geometric\n",
    "#import torch\n",
    "#from torch_geometric.data import Data\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df1 and df2 are already defined and 'edge_feature_cols' is defined\n",
    "# Example: edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "\n",
    "# Prepare node features\n",
    "#data_x = torch.tensor(df2.drop(['v_id', 'criticality_label'], axis=1).values, dtype=torch.float)\n",
    "\n",
    "# Prepare edge index\n",
    "#edge_index = torch.tensor(df1[['v_id_1', 'v_id_2']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Prepare edge features\n",
    "#data_edge_attr = torch.tensor(df1[edge_feature_cols].values, dtype=torch.float)\n",
    "\n",
    "# Encode target labels\n",
    "#label_encoder = LabelEncoder()\n",
    "#df2['criticality_label_encoded'] = label_encoder.fit_transform(df2['criticality_label'])\n",
    "#data_y = torch.tensor(df2['criticality_label_encoded'].values, dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "#data1 = Data(x=data_x, edge_index=edge_index, edge_attr=data_edge_attr, y=data_y)\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df1 and df2 are already defined and 'edge_feature_cols' is defined\n",
    "# Example: edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "\n",
    "# Prepare node features\n",
    "data_x = torch.tensor(df2.drop(['v_id', 'criticality_label'], axis=1).values, dtype=torch.float)\n",
    "\n",
    "# Prepare edge index\n",
    "# Subtract 1 from each node index to convert to 0-based indexing\n",
    "edge_index = torch.tensor(df1[['v_id_1', 'v_id_2']].values, dtype=torch.long) - 1\n",
    "edge_index = edge_index.t().contiguous()\n",
    "\n",
    "# Prepare edge features\n",
    "data_edge_attr = torch.tensor(df1[edge_feature_cols].values, dtype=torch.float)\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df2['criticality_label_encoded'] = label_encoder.fit_transform(df2['criticality_label'])\n",
    "data_y = torch.tensor(df2['criticality_label_encoded'].values, dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "data1 = Data(x=data_x, edge_index=edge_index, edge_attr=data_edge_attr, y=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[479, 14], edge_index=[2, 765], edge_attr=[765, 8], y=[479])\n"
     ]
    }
   ],
   "source": [
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=14, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
      "  )\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.890 | Train Acc: 22.72% | Val Loss: 1.81 | Val Acc: 21.28%\n",
      "Epoch  20 | Train Loss: 1.241 | Train Acc: 40.99% | Val Loss: 1.37 | Val Acc: 38.30%\n",
      "Epoch  40 | Train Loss: 1.151 | Train Acc: 50.39% | Val Loss: 1.28 | Val Acc: 46.81%\n",
      "Epoch  60 | Train Loss: 1.081 | Train Acc: 53.79% | Val Loss: 1.29 | Val Acc: 48.94%\n",
      "Epoch  80 | Train Loss: 1.031 | Train Acc: 56.14% | Val Loss: 1.31 | Val Acc: 48.94%\n",
      "Epoch 100 | Train Loss: 0.992 | Train Acc: 56.92% | Val Loss: 1.40 | Val Acc: 40.43%\n",
      "\n",
      "GNN test accuracy: 38.78%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# Assuming 'data1' is already defined as per your previous code\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "\n",
    "class VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sparse.mm(adjacency, x)  # Multiplication with A\n",
    "        return x\n",
    "\n",
    "# Convert the edge index to adjacency matrix and add self-loops\n",
    "adjacency = to_dense_adj(data1.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "# Split indices for training, validation, and testing\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "test_size = num_nodes - (train_size + val_size)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "# Assign these masks to your data object\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h)\n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        h = self.gnn1(x, adjacency)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gnn2(h, adjacency)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs, adjacency):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, adjacency)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    def test(self, data, adjacency):\n",
    "        self.eval()\n",
    "        out = self(data.x, adjacency)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n",
    "# Initialize the GNN\n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gnn = VanillaGNN(num_features, 16, num_classes)\n",
    "print(gnn)\n",
    "\n",
    "# Make sure to add train_mask, val_mask, and test_mask to data1 as needed\n",
    "\n",
    "# Fit and test the model\n",
    "gnn.fit(data1, epochs=100, adjacency=adjacency)\n",
    "acc = gnn.test(data1, adjacency)\n",
    "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.01, Hidden Units: 16, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.01, Hidden Units: 32, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.01, Hidden Units: 64, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.005, Hidden Units: 16, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.005, Hidden Units: 32, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.005, Hidden Units: 64, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.001, Hidden Units: 16, Test Accuracy: 0.4490\n",
      "Learning Rate: 0.001, Hidden Units: 32, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.001, Hidden Units: 64, Test Accuracy: 0.5102\n",
      "\n",
      "Best Model - Learning Rate: 0.001, Hidden Units: 64, Test Accuracy: 0.5102\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_gnn(learning_rate, hidden_units, epochs, adjacency, data, train_mask, val_mask, test_mask):\n",
    "    # Adjust the model's parameters\n",
    "    gnn.gnn1.linear = Linear(data.num_features, hidden_units, bias=False)\n",
    "    gnn.gnn2.linear = Linear(hidden_units, int(data.y.max()) + 1, bias=False)\n",
    "\n",
    "    # Define the optimizer with the given learning rate\n",
    "    optimizer = torch.optim.Adam(gnn.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "    # Training loop\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    gnn.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = gnn(data.x, adjacency)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    gnn.eval()\n",
    "    out = gnn(data.x, adjacency)\n",
    "    acc = accuracy(out.argmax(dim=1)[test_mask], data.y[test_mask])\n",
    "    return acc\n",
    "\n",
    "# Grid search parameters\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "hidden_units_options = [16, 32, 64]\n",
    "epochs = 100\n",
    "\n",
    "# Variables to store the best model's performance\n",
    "best_accuracy = 0.0\n",
    "best_lr = 0\n",
    "best_hu = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hu in hidden_units_options:\n",
    "        acc = train_and_evaluate_gnn(lr, hu, epochs, adjacency, data1, data1.train_mask, data1.val_mask, data1.test_mask)\n",
    "        print(f\"Learning Rate: {lr}, Hidden Units: {hu}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_lr = lr\n",
    "            best_hu = hu\n",
    "\n",
    "print(f\"\\nBest Model - Learning Rate: {best_lr}, Hidden Units: {best_hu}, Test Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gcn1): GCNConv(14, 16)\n",
      "  (gcn2): GCNConv(16, 4)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.958 | Train Acc: 22.19% | Val Loss: 2.12 | Val Acc: 27.66%\n",
      "Epoch  20 | Train Loss: 1.235 | Train Acc: 45.43% | Val Loss: 1.32 | Val Acc: 38.30%\n",
      "Epoch  40 | Train Loss: 1.149 | Train Acc: 47.52% | Val Loss: 1.23 | Val Acc: 44.68%\n",
      "Epoch  60 | Train Loss: 1.097 | Train Acc: 52.22% | Val Loss: 1.25 | Val Acc: 40.43%\n",
      "Epoch  80 | Train Loss: 1.058 | Train Acc: 55.09% | Val Loss: 1.25 | Val Acc: 38.30%\n",
      "Epoch 100 | Train Loss: 1.020 | Train Acc: 56.92% | Val Loss: 1.26 | Val Acc: 36.17%\n",
      "GCN test accuracy: 38.78%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Assuming 'data1' is already defined with x, edge_index, and y\n",
    "\n",
    "# Create train, validation, and test masks\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        predictions = out.argmax(dim=1)\n",
    "        acc = accuracy(predictions[data.test_mask], data.y[data.test_mask])\n",
    "        return acc, predictions\n",
    "\n",
    "# Initialize and train the GCN model\n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gcn = GCN(num_features, 16, num_classes)\n",
    "print(gcn)\n",
    "gcn.fit(data1, epochs=100)\n",
    "\n",
    "# Test the model\n",
    "acc, pred = gcn.test(data1)\n",
    "print(f'GCN test accuracy: {acc*100:.2f}%')\n",
    "#print(f'GCN predictions: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GATv2Conv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/05/1myqmjn90dzg74p2skbdpnz00000gn/T/ipykernel_49420/3634866456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mgat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mgat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/05/1myqmjn90dzg74p2skbdpnz00000gn/T/ipykernel_49420/3634866456.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim_in, dim_h, dim_out, heads)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGATv2Conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         self.gat2 = GATv2Conv(dim_h*heads, dim_out,\n\u001b[1;32m     33\u001b[0m heads=1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GATv2Conv' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Assuming 'data1' is already defined with x, edge_index, and y\n",
    "\n",
    "# Create train, validation, and test masks\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "        self.gat2 = GATv2Conv(dim_h*heads, dim_out,\n",
    "heads=1)\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.6, training=self.training)\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.elu(h)\n",
    "        h = F.dropout(h, p=0.6, training=self.training)\n",
    "        h = self.gat2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "lr=0.01, weight_decay=0.01)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask],\n",
    "data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask],\n",
    "data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].\n",
    "argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss:{loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss:{val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask],\n",
    "    data.y[data.test_mask])\n",
    "        return acc\n",
    "    \n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gat = GAT(num_features, 32, num_classes)\n",
    "gat.fit(data, epochs=100)\n",
    "\n",
    "acc = gat.test(data)\n",
    "print(f'GAT test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
