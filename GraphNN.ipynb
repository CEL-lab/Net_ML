{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('edges3.csv')\n",
    "df2 = pd.read_excel('node3_cml.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_id</th>\n",
       "      <th>v_id_1</th>\n",
       "      <th>v_id_2</th>\n",
       "      <th>voltage</th>\n",
       "      <th>cables</th>\n",
       "      <th>wires</th>\n",
       "      <th>length_m</th>\n",
       "      <th>r</th>\n",
       "      <th>x</th>\n",
       "      <th>c</th>\n",
       "      <th>i_th_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43379.0</td>\n",
       "      <td>1.735160</td>\n",
       "      <td>13.881280</td>\n",
       "      <td>498.8585</td>\n",
       "      <td>112.78540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72686.0</td>\n",
       "      <td>0.227144</td>\n",
       "      <td>18.171500</td>\n",
       "      <td>995.7982</td>\n",
       "      <td>1511.86880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33943.0</td>\n",
       "      <td>0.678860</td>\n",
       "      <td>10.861760</td>\n",
       "      <td>390.3445</td>\n",
       "      <td>176.50360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33471.0</td>\n",
       "      <td>0.209194</td>\n",
       "      <td>8.367750</td>\n",
       "      <td>458.5527</td>\n",
       "      <td>348.09840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28163.0</td>\n",
       "      <td>0.088009</td>\n",
       "      <td>7.040750</td>\n",
       "      <td>385.8331</td>\n",
       "      <td>585.79040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>761.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>0.253184</td>\n",
       "      <td>9.0988</td>\n",
       "      <td>2.10912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>762.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.196608</td>\n",
       "      <td>7.0656</td>\n",
       "      <td>2.11640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>1.008832</td>\n",
       "      <td>36.2549</td>\n",
       "      <td>8.19676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>764.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>10.3891</td>\n",
       "      <td>2.70972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>765.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.018088</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>6.3480</td>\n",
       "      <td>1.95416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      l_id  v_id_1  v_id_2   voltage  cables  wires  length_m         r  \\\n",
       "0      1.0     1.0     2.0  220000.0     3.0    2.0   43379.0  1.735160   \n",
       "1      2.0     3.0     4.0  380000.0     6.0    4.0   72686.0  0.227144   \n",
       "2      3.0     5.0     6.0  220000.0     6.0    2.0   33943.0  0.678860   \n",
       "3      4.0     7.0     5.0  380000.0     3.0    4.0   33471.0  0.209194   \n",
       "4      5.0     8.0     9.0  380000.0     6.0    4.0   28163.0  0.088009   \n",
       "..     ...     ...     ...       ...     ...    ...       ...       ...   \n",
       "760  761.0   474.0   476.0  220000.0     9.0    1.8     770.0  0.038376   \n",
       "761  762.0   475.0   476.0  220000.0     9.0    2.4     661.0  0.020584   \n",
       "762  763.0   477.0   479.0  220000.0    12.0    2.0    3315.0  0.126104   \n",
       "763  764.0   225.0   479.0  220000.0    12.0    2.0     897.0  0.033360   \n",
       "764  765.0   478.0   479.0  220000.0    12.0    2.4     488.0  0.018088   \n",
       "\n",
       "             x         c    i_th_max  \n",
       "0    13.881280  498.8585   112.78540  \n",
       "1    18.171500  995.7982  1511.86880  \n",
       "2    10.861760  390.3445   176.50360  \n",
       "3     8.367750  458.5527   348.09840  \n",
       "4     7.040750  385.8331   585.79040  \n",
       "..         ...       ...         ...  \n",
       "760   0.253184    9.0988     2.10912  \n",
       "761   0.196608    7.0656     2.11640  \n",
       "762   1.008832   36.2549     8.19676  \n",
       "763   0.289088   10.3891     2.70972  \n",
       "764   0.176640    6.3480     1.95416  \n",
       "\n",
       "[765 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v_id</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>typ</th>\n",
       "      <th>voltage</th>\n",
       "      <th>eigen_centrality</th>\n",
       "      <th>closeness_centrality</th>\n",
       "      <th>clustering_coefficient</th>\n",
       "      <th>load_centrality</th>\n",
       "      <th>avg_shortest_path_length</th>\n",
       "      <th>average_neighbor_degree</th>\n",
       "      <th>node_strength</th>\n",
       "      <th>criticality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.522576</td>\n",
       "      <td>52.360409</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.113210</td>\n",
       "      <td>52.543853</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>1.838136e-31</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1260000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.389745</td>\n",
       "      <td>52.026313</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>7.071928e-44</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.125265</td>\n",
       "      <td>52.538264</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>1.813950e-37</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.366275</td>\n",
       "      <td>52.284647</td>\n",
       "      <td>substation</td>\n",
       "      <td>380000</td>\n",
       "      <td>7.071928e-44</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2400000</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>475</td>\n",
       "      <td>8.872260</td>\n",
       "      <td>50.129725</td>\n",
       "      <td>substation</td>\n",
       "      <td>110000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>476</td>\n",
       "      <td>8.743261</td>\n",
       "      <td>50.162338</td>\n",
       "      <td>auxillary_T_node</td>\n",
       "      <td>220000</td>\n",
       "      <td>6.141411e-44</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>660000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>477</td>\n",
       "      <td>7.957537</td>\n",
       "      <td>47.572159</td>\n",
       "      <td>substation</td>\n",
       "      <td>220000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>478</td>\n",
       "      <td>7.958491</td>\n",
       "      <td>47.579148</td>\n",
       "      <td>generator</td>\n",
       "      <td>380000</td>\n",
       "      <td>9.305167e-51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220000</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>479</td>\n",
       "      <td>7.950278</td>\n",
       "      <td>47.591674</td>\n",
       "      <td>auxillary_T_node</td>\n",
       "      <td>220000</td>\n",
       "      <td>2.087394e-21</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>660000</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     v_id        lon        lat               typ  voltage  eigen_centrality  \\\n",
       "0       1   9.522576  52.360409        substation   220000      9.305167e-51   \n",
       "1       2   9.113210  52.543853        substation   220000      1.838136e-31   \n",
       "2       3   9.389745  52.026313        substation   380000      7.071928e-44   \n",
       "3       4   9.125265  52.538264        substation   380000      1.813950e-37   \n",
       "4       5  10.366275  52.284647        substation   380000      7.071928e-44   \n",
       "..    ...        ...        ...               ...      ...               ...   \n",
       "474   475   8.872260  50.129725        substation   110000      9.305167e-51   \n",
       "475   476   8.743261  50.162338  auxillary_T_node   220000      6.141411e-44   \n",
       "476   477   7.957537  47.572159        substation   220000      9.305167e-51   \n",
       "477   478   7.958491  47.579148         generator   380000      9.305167e-51   \n",
       "478   479   7.950278  47.591674  auxillary_T_node   220000      2.087394e-21   \n",
       "\n",
       "     closeness_centrality  clustering_coefficient  load_centrality  \\\n",
       "0                0.000000                    0.00         0.000000   \n",
       "1                0.006834                    0.05         0.000197   \n",
       "2                0.004184                    0.05         0.000171   \n",
       "3                0.006538                    0.00         0.000395   \n",
       "4                0.004184                    0.00         0.000110   \n",
       "..                    ...                     ...              ...   \n",
       "474              0.000000                    0.00         0.000000   \n",
       "475              0.006276                    0.00         0.000000   \n",
       "476              0.000000                    0.00         0.000000   \n",
       "477              0.000000                    0.00         0.000000   \n",
       "478              0.009375                    0.00         0.000000   \n",
       "\n",
       "     avg_shortest_path_length  average_neighbor_degree  node_strength  \\\n",
       "0                    2.222222                 3.000000         220000   \n",
       "1                    1.500000                 1.333333        1260000   \n",
       "2                    3.000000                 1.000000        1900000   \n",
       "3                    2.350000                 2.000000        1900000   \n",
       "4                    1.500000                 1.333333        2400000   \n",
       "..                        ...                      ...            ...   \n",
       "474                  0.500000                 0.000000         220000   \n",
       "475                  0.000000                 0.000000         660000   \n",
       "476                  0.500000                 0.000000         220000   \n",
       "477                  0.500000                 0.000000         220000   \n",
       "478                  0.000000                 0.000000         660000   \n",
       "\n",
       "    criticality_label  \n",
       "0                 Low  \n",
       "1              Severe  \n",
       "2              Severe  \n",
       "3              Severe  \n",
       "4              Severe  \n",
       "..                ...  \n",
       "474               Low  \n",
       "475              High  \n",
       "476               Low  \n",
       "477               Low  \n",
       "478              High  \n",
       "\n",
       "[479 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Assuming df1 and df2 are your DataFrame objects\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes with attributes\n",
    "for _, row in df2.iterrows():\n",
    "    G.add_node(row['v_id'], \n",
    "               lon=row['lon'], \n",
    "               lat=row['lat'], \n",
    "               voltage=row['voltage'], \n",
    "               typ=row['typ'], \n",
    "               criticality_label=row['criticality_label'])\n",
    "\n",
    "# Add edges\n",
    "for _, row in df1.iterrows():\n",
    "    G.add_edge(row['v_id_1'], row['v_id_2'], \n",
    "               voltage=row['voltage'], \n",
    "               length_m=row['length_m'])\n",
    "\n",
    "# Export to GraphML\n",
    "nx.write_graphml(G, \"SciGrid.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Handle Categorical Variable in df2\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode the 'typ' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "typ_encoded = encoder.fit_transform(df2[['typ']])\n",
    "\n",
    "# Convert to DataFrame and concatenate with df2\n",
    "typ_encoded_df = pd.DataFrame(typ_encoded, columns=encoder.get_feature_names_out(['typ']))\n",
    "df2 = pd.concat([df2.drop('typ', axis=1), typ_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Numerical Features in df2 and df1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize node features in df2\n",
    "node_feature_cols = [col for col in df2.columns if col not in ['v_id', 'criticality_label', *encoder.get_feature_names_out(['typ'])]]\n",
    "scaler = StandardScaler()\n",
    "df2[node_feature_cols] = scaler.fit_transform(df2[node_feature_cols])\n",
    "\n",
    "# Standardize edge features in df1\n",
    "edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "df1[edge_feature_cols] = scaler.fit_transform(df1[edge_feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.2-cp39-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 59.6 MB 7.7 MB/s eta 0:00:012\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[K     |████████████████████████████████| 168 kB 12.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch) (4.7.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.4-cp39-cp39-macosx_10_9_universal2.whl (17 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: mpmath, MarkupSafe, sympy, jinja2, fsspec, filelock, torch\n",
      "Successfully installed MarkupSafe-2.1.4 filelock-3.13.1 fsspec-2023.12.2 jinja2-3.1.3 mpmath-1.3.0 sympy-1.12 torch-2.1.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: jinja2 in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (3.1.3)\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: numpy in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (1.26.2)\n",
      "Requirement already satisfied: scipy in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (1.11.4)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from jinja2->torch_geometric) (2.1.4)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mmishkaturrahman/Library/Python/3.9/lib/python/site-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, tqdm, requests, torch-geometric\n",
      "Successfully installed certifi-2023.11.17 charset-normalizer-3.3.2 idna-3.6 requests-2.31.0 torch-geometric-2.4.0 tqdm-4.66.1 urllib3-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data for PyTorch Geometric\n",
    "#import torch\n",
    "#from torch_geometric.data import Data\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df1 and df2 are already defined and 'edge_feature_cols' is defined\n",
    "# Example: edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "\n",
    "# Prepare node features\n",
    "#data_x = torch.tensor(df2.drop(['v_id', 'criticality_label'], axis=1).values, dtype=torch.float)\n",
    "\n",
    "# Prepare edge index\n",
    "#edge_index = torch.tensor(df1[['v_id_1', 'v_id_2']].values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Prepare edge features\n",
    "#data_edge_attr = torch.tensor(df1[edge_feature_cols].values, dtype=torch.float)\n",
    "\n",
    "# Encode target labels\n",
    "#label_encoder = LabelEncoder()\n",
    "#df2['criticality_label_encoded'] = label_encoder.fit_transform(df2['criticality_label'])\n",
    "#data_y = torch.tensor(df2['criticality_label_encoded'].values, dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "#data1 = Data(x=data_x, edge_index=edge_index, edge_attr=data_edge_attr, y=data_y)\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming df1 and df2 are already defined and 'edge_feature_cols' is defined\n",
    "# Example: edge_feature_cols = ['voltage', 'cables', 'wires', 'length_m', 'r', 'x', 'c', 'i_th_max']\n",
    "\n",
    "# Prepare node features\n",
    "data_x = torch.tensor(df2.drop(['v_id', 'criticality_label'], axis=1).values, dtype=torch.float)\n",
    "\n",
    "# Prepare edge index\n",
    "# Subtract 1 from each node index to convert to 0-based indexing\n",
    "edge_index = torch.tensor(df1[['v_id_1', 'v_id_2']].values, dtype=torch.long) - 1\n",
    "edge_index = edge_index.t().contiguous()\n",
    "\n",
    "# Prepare edge features\n",
    "data_edge_attr = torch.tensor(df1[edge_feature_cols].values, dtype=torch.float)\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "df2['criticality_label_encoded'] = label_encoder.fit_transform(df2['criticality_label'])\n",
    "data_y = torch.tensor(df2['criticality_label_encoded'].values, dtype=torch.long)\n",
    "\n",
    "# Create Data object\n",
    "data1 = Data(x=data_x, edge_index=edge_index, edge_attr=data_edge_attr, y=data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[479, 14], edge_index=[2, 765], edge_attr=[765, 8], y=[479])\n"
     ]
    }
   ],
   "source": [
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=14, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
      "  )\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.906 | Train Acc: 29.50% | Val Loss: 2.15 | Val Acc: 23.40%\n",
      "Epoch  20 | Train Loss: 1.213 | Train Acc: 46.74% | Val Loss: 1.42 | Val Acc: 31.91%\n",
      "Epoch  40 | Train Loss: 1.148 | Train Acc: 52.48% | Val Loss: 1.45 | Val Acc: 38.30%\n",
      "Epoch  60 | Train Loss: 1.089 | Train Acc: 55.61% | Val Loss: 1.53 | Val Acc: 40.43%\n",
      "Epoch  80 | Train Loss: 1.037 | Train Acc: 56.14% | Val Loss: 1.63 | Val Acc: 38.30%\n",
      "Epoch 100 | Train Loss: 0.990 | Train Acc: 56.14% | Val Loss: 1.81 | Val Acc: 38.30%\n",
      "Epoch 120 | Train Loss: 0.951 | Train Acc: 57.96% | Val Loss: 1.93 | Val Acc: 38.30%\n",
      "Epoch 140 | Train Loss: 0.925 | Train Acc: 59.27% | Val Loss: 2.09 | Val Acc: 36.17%\n",
      "Epoch 160 | Train Loss: 0.904 | Train Acc: 59.79% | Val Loss: 2.21 | Val Acc: 34.04%\n",
      "Epoch 180 | Train Loss: 0.883 | Train Acc: 60.05% | Val Loss: 2.32 | Val Acc: 34.04%\n",
      "Epoch 200 | Train Loss: 0.853 | Train Acc: 61.88% | Val Loss: 2.47 | Val Acc: 36.17%\n",
      "\n",
      "GNN test accuracy: 42.86%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# Assuming 'data1' is already defined as per your previous code\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "\n",
    "class VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sparse.mm(adjacency, x)  # Multiplication with A\n",
    "        return x\n",
    "\n",
    "# Convert the edge index to adjacency matrix and add self-loops\n",
    "adjacency = to_dense_adj(data1.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "# Split indices for training, validation, and testing\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "test_size = num_nodes - (train_size + val_size)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "# Assign these masks to your data object\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h)\n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        h = self.gnn1(x, adjacency)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gnn2(h, adjacency)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs, adjacency):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, adjacency)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    def test(self, data, adjacency):\n",
    "        self.eval()\n",
    "        out = self(data.x, adjacency)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n",
    "# Initialize the GNN\n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gnn = VanillaGNN(num_features, 16, num_classes)\n",
    "print(gnn)\n",
    "\n",
    "# Make sure to add train_mask, val_mask, and test_mask to data1 as needed\n",
    "\n",
    "# Fit and test the model\n",
    "gnn.fit(data1, epochs=200, adjacency=adjacency)\n",
    "acc = gnn.test(data1, adjacency)\n",
    "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.4082\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.3878\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.3265\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.4490\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.3265\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.3061\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.3878\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.3878\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.3469\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.3265\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.2857\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.3878\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.3265\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.3061\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.3061\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.3265\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.4082\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.3673\n",
      "\n",
      "Best Model - Learning Rate: 0.01, Hidden Units: 16, Test Accuracy: 0.4694\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_gnn(learning_rate, hidden_units, epochs, adjacency, data, train_mask, val_mask, test_mask):\n",
    "    # Adjust the model's parameters\n",
    "    gnn.gnn1.linear = Linear(data.num_features, hidden_units, bias=False)\n",
    "    gnn.gnn2.linear = Linear(hidden_units, int(data.y.max()) + 1, bias=False)\n",
    "\n",
    "    # Define the optimizer with the given learning rate\n",
    "    optimizer = torch.optim.Adam(gnn.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "    # Training loop\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    gnn.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = gnn(data.x, adjacency)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    gnn.eval()\n",
    "    out = gnn(data.x, adjacency)\n",
    "    acc = accuracy(out.argmax(dim=1)[test_mask], data.y[test_mask])\n",
    "    return acc\n",
    "\n",
    "# Grid search parameters\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "hidden_units_options = [16, 32, 64]\n",
    "epochs_options = [100, 150, 200]\n",
    "\n",
    "# Variables to store the best model's performance\n",
    "best_accuracy = 0.0\n",
    "best_lr = 0\n",
    "best_hu = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hu in hidden_units_options:\n",
    "        for ep in epochs_options:\n",
    "            acc = train_and_evaluate_gnn(lr, hu, ep, adjacency, data1, data1.train_mask, data1.val_mask, data1.test_mask)\n",
    "            print(f\"Learning Rate: {lr}, Hidden Units: {hu}, Epochs: {ep}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_lr = lr\n",
    "                best_hu = hu\n",
    "\n",
    "\n",
    "print(f\"\\nBest Model - Learning Rate: {best_lr}, Hidden Units: {best_hu}, Test Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gcn1): GCNConv(14, 16)\n",
      "  (gcn2): GCNConv(16, 4)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.599 | Train Acc: 24.02% | Val Loss: 1.68 | Val Acc: 21.28%\n",
      "Epoch  20 | Train Loss: 1.247 | Train Acc: 42.82% | Val Loss: 1.40 | Val Acc: 34.04%\n",
      "Epoch  40 | Train Loss: 1.146 | Train Acc: 48.56% | Val Loss: 1.33 | Val Acc: 40.43%\n",
      "Epoch  60 | Train Loss: 1.072 | Train Acc: 52.22% | Val Loss: 1.32 | Val Acc: 40.43%\n",
      "Epoch  80 | Train Loss: 1.017 | Train Acc: 55.35% | Val Loss: 1.35 | Val Acc: 40.43%\n",
      "Epoch 100 | Train Loss: 0.973 | Train Acc: 58.22% | Val Loss: 1.35 | Val Acc: 40.43%\n",
      "GCN test accuracy: 53.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Assuming 'data1' is already defined with x, edge_index, and y\n",
    "\n",
    "# Create train, validation, and test masks\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "# Define GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.gcn1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        predictions = out.argmax(dim=1)\n",
    "        acc = accuracy(predictions[data.test_mask], data.y[data.test_mask])\n",
    "        return acc, predictions\n",
    "\n",
    "# Initialize and train the GCN model\n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gcn = GCN(num_features, 16, num_classes)\n",
    "print(gcn)\n",
    "gcn.fit(data1, epochs=100)\n",
    "\n",
    "# Test the model\n",
    "acc, pred = gcn.test(data1)\n",
    "print(f'GCN test accuracy: {acc*100:.2f}%')\n",
    "#print(f'GCN predictions: {pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.5510\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.5306\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.4082\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.4490\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.4490\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.3878\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.5510\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.5306\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.5306\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.6122\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.5306\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.4082\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.3673\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.5102\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.4898\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.5714\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.5102\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.5102\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.5306\n",
      "\n",
      "Best Model - Learning Rate: 0.005, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.6122\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_gcn(learning_rate, hidden_units, epoch_count, data, train_mask, val_mask, test_mask):\n",
    "    # Adjust the model's parameters\n",
    "    gcn.gcn1 = GCNConv(data.num_features, hidden_units)\n",
    "    gcn.gcn2 = GCNConv(hidden_units, int(data.y.max()) + 1)\n",
    "\n",
    "    # Define the optimizer with the given learning rate\n",
    "    optimizer = torch.optim.Adam(gcn.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "    # Training loop\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    gcn.train()\n",
    "    for epoch in range(epoch_count):\n",
    "        optimizer.zero_grad()\n",
    "        out = gcn(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    gcn.eval()\n",
    "    out = gcn(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[test_mask], data.y[test_mask])\n",
    "    return acc\n",
    "\n",
    "# Grid search parameters\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "hidden_units_options = [16, 32, 64]\n",
    "epochs_options = [100, 150, 200]\n",
    "\n",
    "# Variables to store the best model's performance\n",
    "best_accuracy = 0.0\n",
    "best_lr = 0\n",
    "best_hu = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hu in hidden_units_options:\n",
    "        for ep in epochs_options:\n",
    "            acc = train_and_evaluate_gcn(lr, hu, ep, data1, data1.train_mask, data1.val_mask, data1.test_mask)\n",
    "            print(f\"Learning Rate: {lr}, Hidden Units: {hu}, Epochs: {ep}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_lr = lr\n",
    "                best_hu = hu\n",
    "                best_epoch = ep\n",
    "\n",
    "print(f\"\\nBest Model - Learning Rate: {best_lr}, Hidden Units: {best_hu}, Epochs: {best_epoch}, Test Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.527 | Train Acc: 26.89% | Val Loss: 1.49 | Val Acc: 34.04%\n",
      "Epoch  20 | Train Loss: 1.295 | Train Acc: 38.64% | Val Loss: 1.34 | Val Acc: 29.79%\n",
      "Epoch  40 | Train Loss: 1.246 | Train Acc: 40.47% | Val Loss: 1.32 | Val Acc: 42.55%\n",
      "Epoch  60 | Train Loss: 1.246 | Train Acc: 40.73% | Val Loss: 1.23 | Val Acc: 40.43%\n",
      "Epoch  80 | Train Loss: 1.214 | Train Acc: 43.60% | Val Loss: 1.26 | Val Acc: 31.91%\n",
      "Epoch 100 | Train Loss: 1.207 | Train Acc: 44.13% | Val Loss: 1.24 | Val Acc: 42.55%\n",
      "GAT test accuracy: 59.18%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "# Assuming 'data1' is already defined with x, edge_index, and y\n",
    "\n",
    "# Create train, validation, and test masks\n",
    "num_nodes = data1.num_nodes\n",
    "indices = torch.randperm(num_nodes)\n",
    "\n",
    "train_size = int(num_nodes * 0.8)\n",
    "val_size = int(num_nodes * 0.1)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[indices[:train_size]] = True\n",
    "val_mask[indices[train_size:train_size + val_size]] = True\n",
    "test_mask[indices[train_size + val_size:]] = True\n",
    "\n",
    "data1.train_mask = train_mask\n",
    "data1.val_mask = val_mask\n",
    "data1.test_mask = test_mask\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "        self.gat2 = GATv2Conv(dim_h * heads, dim_out, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.6, training=self.training)\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.elu(h)\n",
    "        h = F.dropout(h, p=0.6, training=self.training)\n",
    "        h = self.gat2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=0.01)\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, data.edge_index)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n",
    "# Initialize and train the GAT model\n",
    "num_features = data1.num_features\n",
    "num_classes = int(data1.y.max()) + 1\n",
    "gat = GAT(num_features, 32, num_classes)\n",
    "gat.fit(data1, epochs=100)\n",
    "\n",
    "# Test the GAT model\n",
    "acc = gat.test(data1)\n",
    "print(f'GAT test accuracy: {acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.6939\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.01, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.7143\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.6327\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.01, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.6122\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.6939\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.6327\n",
      "Learning Rate: 0.01, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.6122\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.6122\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.6939\n",
      "Learning Rate: 0.005, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.5714\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.6531\n",
      "Learning Rate: 0.005, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.7143\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.005, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.6735\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 100, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 150, Test Accuracy: 0.4490\n",
      "Learning Rate: 0.001, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 100, Test Accuracy: 0.4286\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 150, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.001, Hidden Units: 32, Epochs: 200, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 100, Test Accuracy: 0.4694\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 150, Test Accuracy: 0.5714\n",
      "Learning Rate: 0.001, Hidden Units: 64, Epochs: 200, Test Accuracy: 0.5510\n",
      "\n",
      "Best Model - Learning Rate: 0.01, Hidden Units: 16, Epochs: 200, Test Accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_gat(learning_rate, hidden_units, epochs, data, train_mask, val_mask, test_mask, heads=8):\n",
    "    # Adjust the model's parameters\n",
    "    gat.gat1 = GATv2Conv(data.num_features, hidden_units, heads=heads)\n",
    "    gat.gat2 = GATv2Conv(hidden_units * heads, int(data.y.max()) + 1, heads=1)\n",
    "\n",
    "    # Define the optimizer with the given learning rate\n",
    "    optimizer = torch.optim.Adam(gat.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "\n",
    "    # Training loop\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    gat.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = gat(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    gat.eval()\n",
    "    out = gat(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[test_mask], data.y[test_mask])\n",
    "    return acc\n",
    "\n",
    "# Grid search parameters\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "hidden_units_options = [16, 32, 64]\n",
    "epochs_options = [100, 150, 200]\n",
    "\n",
    "# Variables to store the best model's performance\n",
    "best_accuracy = 0.0\n",
    "best_lr = 0\n",
    "best_hu = 0\n",
    "best_epoch = 0\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for hu in hidden_units_options:\n",
    "        for ep in epochs_options:\n",
    "            acc = train_and_evaluate_gat(lr, hu, ep, data1, data1.train_mask, data1.val_mask, data1.test_mask)\n",
    "            print(f\"Learning Rate: {lr}, Hidden Units: {hu}, Epochs: {ep}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_lr = lr\n",
    "                best_hu = hu\n",
    "                best_epoch = ep\n",
    "\n",
    "print(f\"\\nBest Model - Learning Rate: {best_lr}, Hidden Units: {best_hu}, Epochs: {best_epoch}, Test Accuracy: {best_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
